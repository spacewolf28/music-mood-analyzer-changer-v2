# backend/inference/full_pipeline.py

from pathlib import Path
import time

from .analyze import analyzer
from .prompt_builder import PromptBuilder
from .melody_extractor import MelodyExtractor
from .melody_transformer import MelodyTransformer
from .generate_music import MusicGenerator


class FullMusicPipeline:
    """
    æ–¹æ¡ˆ Aï¼šå¤š attempt è‡ªåŠ¨å†ç”Ÿæˆ + ä¸æ‰éŸ³ç‰ˆæµæ°´çº¿

    æµç¨‹ï¼š
    - ä½¿ç”¨ä½ çš„ style/emotion æ¨¡å‹åˆ†æåŸæ­Œ
    - ä½¿ç”¨ PromptBuilder æ„é€ éš attempt å˜åŒ–çš„ prompt
    - ä½¿ç”¨ MelodyExtractor + MelodyTransformer é€æ­¥å¼±åŒ–/å˜å½¢æ—‹å¾‹
    - ä½¿ç”¨ MusicGen-medium ç”Ÿæˆ ~15 ç§’éŸ³ä¹ï¼ˆå¸¦ anti-collapseï¼‰
    - å†ç”¨ä½ çš„æ¨¡å‹åˆ†æç”Ÿæˆç»“æœï¼Œæ ¹æ® style/emotion å‘½ä¸­æ‰“åˆ†ï¼Œé€‰æœ€ä½³ç‰ˆæœ¬
    """

    def __init__(self):
        self.analyzer = analyzer
        self.prompt_builder = PromptBuilder()
        self.melody_extractor = MelodyExtractor()
        self.melody_transformer = MelodyTransformer()
        self.music_generator = MusicGenerator()

    @staticmethod
    def score_generation(
        predicted_style: str,
        predicted_emotion: str,
        target_style: str,
        target_emotion: str,
    ) -> int:
        """
        ç®€å•è¯„åˆ†ï¼š
        - style å‘½ä¸­ +1
        - emotion å‘½ä¸­ +1
        """
        score = 0
        if predicted_style and predicted_style.lower() == target_style.lower():
            score += 1
        if predicted_emotion and predicted_emotion.lower() == target_emotion.lower():
            score += 1
        return score

    @staticmethod
    def guidance_for_attempt(attempt: int) -> float:
        """
        å°è¯•æ¬¡æ•° â†’ guidance_scaleï¼š
        - 1: 3.8ï¼ˆæ—‹å¾‹æœ€ç¨³ï¼‰
        - 2: 3.6
        - 3: 3.4
        - >=4: 3.2
        """
        if attempt <= 1:
            return 3.8
        elif attempt == 2:
            return 3.6
        elif attempt == 3:
            return 3.4
        else:
            return 3.2

    def process(
        self,
        audio_path: str,
        target_style: str,
        target_emotion: str,
        output_dir: str = "backend/output",
        max_attempts: int = 4,
    ):
        audio_path = Path(audio_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        if not audio_path.is_file():
            raise FileNotFoundError(f"Input audio not found: {audio_path}")

        # 1. ç”¨ä½ çš„æ¨¡å‹åˆ†æåŸæ­Œ
        print("ğŸ” [1/6] Analyzing original audio with your models...")
        analysis = self.analyzer.analyze(str(audio_path))
        orig_style = analysis.get("style")
        orig_emotion = analysis.get("emotion")
        style_prob = analysis.get("style_prob")
        emotion_prob = analysis.get("emotion_prob")

        print(f"   â†’ Input Style:   {orig_style}")
        print(f"   â†’ Input Emotion: {orig_emotion}")

        # å…¨å±€è®°å½•æœ€ä½³ç»“æœ
        best_score = -1
        best_output_path: str | None = None
        best_result: dict | None = None

        print("\nğŸ¶ [2/6] Start Auto-Regenerate loop...")
        for attempt in range(1, max_attempts + 1):
            print(f"\n================ ATTEMPT {attempt}/{max_attempts} ================")

            # 2. æ„é€  Prompt
            print("ğŸ§  Building prompt...")
            prompt = PromptBuilder.build_prompt(
                target_style=target_style,
                target_emotion=target_emotion,
                orig_style=orig_style,
                orig_emotion=orig_emotion,
                style_prob=style_prob,
                emotion_prob=emotion_prob,
                attempt=attempt,
            )
            print("----- Prompt -----")
            print(prompt)
            print("------------------")

            # 3. Melody æå–ï¼ˆéš attempt æ”¹å˜é•¿åº¦ï¼‰+ å˜å½¢
            print("\nğŸ¼ Extracting & transforming melody...")
            weaken_level = attempt - 1
            raw_melody_path = self.melody_extractor.extract_melody_to_wav(
                str(audio_path),
                target_style=target_style,
                target_emotion=target_emotion,
                strength=0.9,
                output_path=output_dir / f"melody_attempt_{attempt}.wav",
                weaken_level=weaken_level,
            )

            transformed_melody_path = self.melody_transformer.transform(
                raw_melody_path, attempt=attempt
            )

            # 4. è°ƒç”¨ MusicGen ç”Ÿæˆ
            print("\nğŸ§ Generating with MusicGen (medium)...")
            output_audio_path = output_dir / f"generated_attempt_{attempt}.wav"
            guidance_scale = self.guidance_for_attempt(attempt)

            self.music_generator.generate_with_melody(
                prompt=prompt,
                melody_path=str(transformed_melody_path),
                output_path=str(output_audio_path),
                target_seconds=15.0,
                guidance_scale=guidance_scale,
                temperature=1.0,
                top_p=0.95,
                do_sample=True,
            )

            # 5. ä½¿ç”¨ä½ çš„æ¨¡å‹åˆ†æç”Ÿæˆç»“æœ
            print("\nğŸ“Š Analyzing generated audio with your models...")
            gen_result = self.analyzer.analyze(str(output_audio_path))
            pred_style = gen_result.get("style")
            pred_emotion = gen_result.get("emotion")

            print(f"   â†’ Generated Style:   {pred_style}")
            print(f"   â†’ Generated Emotion: {pred_emotion}")

            score = self.score_generation(
                pred_style, pred_emotion,
                target_style, target_emotion,
            )
            print(f"â¡ Score for this attempt: {score} / 2")

            # è®°å½•æœ€ä½³ç»“æœ
            if score > best_score:
                best_score = score
                best_output_path = str(output_audio_path)
                best_result = gen_result

            # style + emotion å…¨å‘½ä¸­å¯ä»¥æå‰ stop
            if score == 2:
                print("âœ¨ Perfect style + emotion match! Stop early.")
                break

            time.sleep(1)

        # 6. è¾“å‡ºæœ€ç»ˆæœ€ä½³ç»“æœ
        print("\nğŸ‰ [6/6] Final Best Result:")
        if best_result is None or best_output_path is None:
            print("âš  æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•ç»“æœï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„æ—¥å¿—ã€‚")
            return None

        print("Best Style:   ", best_result.get("style"))
        print("Best Emotion: ", best_result.get("emotion"))
        print("Best Score:   ", best_score)
        print("Best File:    ", best_output_path)

        print("\n============== CHANGE SUMMARY ==============")
        print(f"Style:   {orig_style} â†’ {best_result.get('style')}")
        print(f"Emotion: {orig_emotion} â†’ {best_result.get('emotion')}")
        print("===========================================\n")

        return best_output_path


if __name__ == "__main__":
    pipeline = FullMusicPipeline()

    INPUT_AUDIO = r"backend/test_audio.wav"   # æ¢æˆä½ çš„æµ‹è¯•éŸ³é¢‘
    TARGET_STYLE = "rock"                     # rock / jazz / classical / pop / electronic
    TARGET_EMOTION = "happy"                  # angry / funny / happy / sad / scary / tender

    pipeline.process(
        audio_path=INPUT_AUDIO,
        target_style=TARGET_STYLE,
        target_emotion=TARGET_EMOTION,
        output_dir="backend/output",
        max_attempts=4,
    )
