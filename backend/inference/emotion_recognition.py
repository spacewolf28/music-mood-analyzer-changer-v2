import os
import numpy as np
import joblib
import librosa

from backend.features.yamnet_extract import extract_yamnet_embedding

# === è·¯å¾„ ===
MODEL_PATH = "backend/models/emotion_model.pkl"

# === åŠ è½½æ¨¡å‹ ===
emotion_model = joblib.load(MODEL_PATH)

# === ä½ è‡ªå·±çš„æ ‡ç­¾é¡ºåº ===
emotion_labels = [
    "angry",
    "funny",
    "happy",
    "sad",
    "scary",
    "tender"
]


def predict_emotion(audio_path: str):
    """
    è¾“å…¥éŸ³é¢‘è·¯å¾„ï¼Œè¿”å›:
        emotion_label: str
        prob_dict: dict[label -> prob]
    """

    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"Audio file not found: {audio_path}")

    # 1. æå– YAMNet embedding
    embedding = extract_yamnet_embedding(audio_path)

    # 2. å¹³å‡å¤šå¸§ï¼ˆè®­ç»ƒä¸€è‡´ï¼‰
    if len(embedding.shape) > 1:
        embedding = embedding.mean(axis=0)

    embedding = embedding.reshape(1, -1)

    # 3. é¢„æµ‹ç±»åˆ«
    pred_idx = emotion_model.predict(embedding)[0]
    emotion = emotion_labels[pred_idx]

    # 4. é¢„æµ‹æ¦‚ç‡ï¼ˆXGBoost / sklearn æ¨¡å‹æ”¯æŒ predict_probaï¼‰
    try:
        prob = emotion_model.predict_proba(embedding)[0]
        prob_dict = {emotion_labels[i]: float(prob[i]) for i in range(len(emotion_labels))}
    except Exception:
        # ä¸‡ä¸€æ¨¡å‹æ²¡æœ‰ prob èƒ½åŠ›ï¼ˆä¸å¤ªå¯èƒ½ï¼‰
        prob_dict = {emotion_labels[i]: (1.0 if i == pred_idx else 0.0) for i in range(len(emotion_labels))}

    return emotion, prob_dict


if __name__ == "__main__":
    test_audio = "backend/test_audio.wav"

    print("ğŸ” æ­£åœ¨åˆ†ææƒ…ç»ª...")
    emotion, prob = predict_emotion(test_audio)
    print(f"ğŸµ è¯†åˆ«ç»“æœï¼š{emotion}")
    print(f"æ¦‚ç‡åˆ†å¸ƒï¼š{prob}")
